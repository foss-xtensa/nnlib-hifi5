#
# Copyright (c) 2018-2024 Cadence Design Systems, Inc.
#
# Permission is hereby granted, free of charge, to any person obtaining
# a copy of this software and associated documentation files (the
# "Software"), to use this Software with Cadence processor cores only and
# not with any other processors and platforms, subject to
# the following conditions:
#
# The above copyright notice and this permission notice shall be included
# in all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
# IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
# CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
# TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
# SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
#

===============================================================================
Cadence HiFi 5 Neural Network (NN) Library
===============================================================================

===============================================================================
Revision History
===============================================================================

Version 3.2.0 API 1.9: September 9, 2024

+ Intermediate Release of HiFi5 NN Library
+ Tested using the RJ-2024.3 tools and xt-clang/xt-clang++ compiler
+ Adds the following kernels:
  xa_nn_dilated_conv2d_std_per_chan_sym8sxsym16s
  xa_nn_batch_matmul_asym8sxasym8s_asym8s
  xa_nn_batch_matmul_sym16sxsym16s_sym16s
  xa_nn_elm_requantize_asym8s_asym8u
  xa_nn_elm_requantize_asym8s_asym16s
  xa_nn_elm_requantize_asym8s_asym16u
  xa_nn_renorm_asym8s_asym8s
  xa_nn_shuffle_3D_8_8
+ Adds _v2 versions of the following kernels of sym8sxasym8s and sym8sxsym16s precisions.
  These kernels add fused min-max activation operation to the existing funcationality to improve performance.
  fully_connected
  conv2d_std
  conv2d
  dilated_conv2d_std
  conv2d_pointwise
  transpose_conv
+ Adds _v2 versions of conv2d_depth (sym8sxasym8s, sym8sxsym16s) and dilated_conv2d_depth (sym8sxasym8s)
  These kernels add fused min-max activation operation to existing functionality to improve performance.
  Only NHWC data-format is supported to improve code size.
+ Adds _v2 versions of matXvec kernels for precisions asym8sxasym8s and sym8sxsym16s.
  These kernels remove mat2/vec2 parameters, assume additional alignment requirements, and add fused min-max
  activation support to the existing functionality.
+ Fixes known issues to improve stability.

Note:
> New _v2 APIs are in beta stage and may change in next release.
> Processor Configuration must be built with the SP-VFP option to compile floating point variants of the kernels.
> The ANN test bench and the supporting libraries need support for the C++11 standard. 
  This is supported only with the Xtensa C library. 

Known issues
> Compiler optimizations are not available for the ANN C++ source files.
> 3 failures were seen in the ANN testcases because of differences in reference code implementations:
    DEPTHWISE_CONV2D_FLOAT_LARGE_2_WEIGHTS_AS_INPUTS
    LOCAL_RESPONSE_NORM_FLOAT_4
    LOCAL_RESPONSE_NORM_FLOAT_4_RELAXED

----------------------------------------------------------------------

Version 3.1.0 API 1.8: May 10, 2024

+ Intermediate Release of HiFi5 NN Library
+ Tested using the RJ-2024.3 tools and xt-clang compiler.
+ Adds support for build on HiFi5S core with core-specific tuning for performance.
+ Adds the following kernels:
  xa_nn_concat_8_8
  xa_nn_split_v_8_8
  xa_nn_transpose_16_16
  xa_nn_elm_requantize_asym8u_asym8s
  xa_nn_softmax_sym16s_16
+ Adds Null Bias support for CONV2D and TRANSPOSED_CONV for quant8 and quant16 datatypes.
+ Improves performance of xa_nn_transpose_8_8 kernel for specific use-cases
+ Fixes known issues to improve stability

Note:
> Processor Configuration must be built with the SP-VFP option to compile floating point variants of the kernels.

----------------------------------------------------------------------

Version 3.0.0 API 1.7: January 12, 2024

+ GA Release of HiFi5 NN Library
+ Tested using the RI-2023.11 tools and xt-clang compiler.
+ Adds the following kernels:
  xa_nn_batch_norm_3D_8_8
  xa_nn_resize_bilinear_8_8
  xa_nn_resize_nearest_neighbour_8_8
+ Adds the asym4sxasym8s data type support for the batched-FC TFLM operator
+ Adds the half-precision float datatype support for the following kernels:
  TANH
  SIGMOID
+ Adds the TFLM CONV operator xa_nn_conv2d_per_chan_sym8sxsym16s. This kernel also supports group convolution.
+ Replaces the group convolution kernel xa_nn_conv2d_group_sym8sxasym8s with xa_nn_conv2d_per_chan_sym8sxasym8s.
+ Removes following kernels (The functionality of these kernels can be obtained from the HiFi Nature DSP Library):
  xa_nn_vec_sigmoid_32_32
  xa_nn_vec_tanh_32_32
  xa_nn_vec_relu_std_32_32
  xa_nn_vec_relu_32_32
  xa_nn_vec_relu1_32_32
  xa_nn_vec_relu6_32_32
  xa_nn_vec_softmax_32_32
+ Fixes known issues to improve stability. Arguments of the xa_nn_conv2d_std_getsize API are altered for one fix.

Note:
> Processor Configuration must be built with the SP-VFP option to compile floating point variants of the kernels.

----------------------------------------------------------------------

Version 2.3.0 API 1.6: September 5, 2023

+ Intermediate Release of HiFi5 NN Library
+ Tested using RI.9 tools, xt-clang/xt-clang++ compiler
+ Adds support for half-precision float data-type for TFLM operators:
  FC
  CONV2D_STD
  CONV_DS
  matmul
+ Adds support for TFLM operatos:
  CONV2D_STD (sym4sxasym8s_sym8s)
  FC (asym4sxasym8s_asym8s)
  Group Convolution (sym8sxasym8s_asym8s)
+ Fixes known issues to improve stability

Note
> Processor Configuration must be built with SP-VFPU option in order to compile 
  floating point variants of the kernels.

----------------------------------------------------------------------

Version 2.2.0 API 1.5: May 25, 2023

+ Intermediate Release of HiFi5 NN Library
+ Tested using RI.9 tools, xt-clang/xt-clang++ compiler
+ Adds support for TRANSPOSE_CONV TFLM operator for quantized int8 data-type
+ Adds support for quantized int16 data-type for TFLM operators:
  ReduceMax
  ReduceMean
  SQUARED_DIFF (with 4D broadcast)
+ Adds support for memmove kernel for int16 data
+ Improves performance for LSTM special case for sigmoid/tanh (tie-based) sym16s kernels
+ Fixes known issues to improve stability

Note
> Processor Configuration must be built with SP-VFPU option in order to compile 
  floating point variants of the kernels.

----------------------------------------------------------------------

Version 2.1.0 API 1.4: April 19, 2023

+ Intermediate Release of HiFi5 NN Library
+ Tested using RI.9 tools, xt-clang/xt-clang++ compiler
+ Adds support for depthwise separable 2D convolution with dilation for
  single precision float and quantized int8 data-types
+ Adds support for TRANSPOSE_CONV TFLM operator for single precision float data-type
+ Adds support for new datatype symmetric quantized int16 for TFLM operators:
  TANH
  SIGMOID
  MUL (with 4D broadcast)
+ Adds supports for TFLM reorg operators:
  PAD (32-bit)
  STRIDED_SLICE (32-bit)
  TRANSPOSE (8-bit)
+ Adds support for new datatypes with for TFLM operators:
  SUB (single precision float inputs/outputs, with 4D broadcast)
  QUANTIZE (single precision float to asymmetric quantized int16)
  DEQUANTIZE (asymmetric quantized int16 to single precision float)
+ Adds kernels xa_nn_matmul_sym8sxsym16s_sym16s, xa_nn_lstm_cell_state_update_16,
  xa_nn_elm_mul_sym16sxsym16s_asym8s and xa_nn_elm_add_16x16_16 for supporting TFLM
  LSTM operator.
+ Adds single precision float support for existing GRU layer
+ Adds Pytorch GRU equations support for precisions 8x16, 16x16 and float32xfloat32 
  to existing GRU layer
+ Adds XA_NNLIB_CNN_EXECUTE_FATAL_INVALID_INPUT_SHAPE error code for CNN layer
+ Adds support for scalar-aligned i/o pointers for xa_nn_matXvec_f32xf32_f32_sigmoid/tanh
+ Add NULL bias-pointer support to kernels
  xa_nn_matXvec_f32xf32_f32, xa_nn_matXvec_f32xf32_f32_tanh/sigmoid
+ Improved performance for kernels xa_nn_matXvec_f32xf32_f32 and
  xa_nn_fully_connected_f32.
+ Improved performance for kernels xa_nn_matmul_f32xf32_f32 and
  xa_nn_conv2d_pointwise_f32.
+ Improved performance for kernel xa_nn_fully_connected_sym8sxsym16s_sym16s.
+ Removes kernel padding requirement for conv2d_std_f32
+ Improves performance of
  conv2d_std_sym8sxasym8s for small kernels sizes (H*W*C <= 8).
+ Fixed high stack usage issue in tanh/sigmoid kernel for float32 datatype.

Note
> Processor Configuration must be built with SP-VFPU option in order to compile 
  floating point variants of the kernels.

----------------------------------------------------------------------

Version 2.0.0 API 1.3: December 16, 2022

+ GA Release of HiFi5 NN Library
+ Tested using RI.9 tools, xt-clang compiler.
+ Adds support for additional data-types (16x16, 8x16, f32xf32) for matmul kernels
+ Updates matXvec testbench to accept matmul (16x16, 8x16, f32xf32) arguments

-------------------------------------------------------------------------------

Version 1.9.0 API 1.3: October 14, 2022

+ Intermediate Release of HiFi5 NN Library
+ Tested using RI.9 tools, xt-clang compiler.
+ Adds support for depthwise-conv2d, matXvec and fully connected kernels for
  sym8sxsym16s datatype
+ Adds support for new datatype for TFLM operator:
  REQUANTIZE (asym16s to asym16s)
  STRIDED_SLICE (int8)
+ Adds support for kernel-dimension greater than input-dimension for standard
  convolution quantized datatypes (TENA-3528)
+ Fixes unexpected behaviour for null bias data pointers for kernel
  xa_nn_matXvec_sym8sxasym8s_asym8s (TENA-3510)
+ Changes input_left_shift handling for returning error to clipping between -31 to +31
  for sigmoid_asym8s, sigmoid_asym8 & tanh_asym8s kernels (TENA-3615)
+ Optimizes performance for following kernels
  broadcast_4D (cases when one input is constant)

-------------------------------------------------------------------------------

Version 1.8.0 API 1.2: August 1, 2022

+ Intermediate Release of HiFi5 NN Library
+ Tested using RI.6 tools, xt-clang compiler.
+ Adds Single Rounding support for TensorFlow Lite Micro operators' quantized
 datatype kernels.
+ Memory model performance improvements for following kernels:
  xa_nn_conv2d_std_per_chan_sym8sxasym8s_asym8s
  xa_nn_conv2d_pointwise_per_chan_sym8sxasym8s_asym8s
  xa_nn_fully_connected_sym8sxasym8s_asym8s
  xa_nn_matXvec_acc_batch_sym8sx8_asym16s
+ Adds matXvec (asym8sxasym8s_asym8s), matmul (per_chan_sym8sxsym16s_sym16s, 
asym8sxasym8s_asym8s), fully_connected (asym8sxasym8s_asym8s) kernels.
+ Adds conv2d_pointwise (per_chan_sym8sxsym16s_sym16s) using corresponding 
matmul.
+ Adds support for asymmetric quantized 16 bit (int16) variants of following
  TFLM operators:
  TRANSPOSE_CONV
  CONV
  LEAKY_RELU
  PAD
  STRIDED_SLICE
+ Adds support for 4D broadcast for following TFLM operators:
  ADD (asymmetric quantized int8 and int16)
  SUB (asymmetric quantized int8 and int16)
  MUL (asymmetric quantized int8)
  SQUARED_DIFF (asymmetric quantized int8)
+ Adds support for new datatypes for quantize TFLM operator:
  QUANTIZE (single precision float to asymmetric quantized int8, 
            asymmetric quantized int8 to asymmetric quantized int8)
+ Improves single rounding performance on new HiFi5 (LX7.1.9 and onwards)
  using new ISA for following kernels:
  xa_nn_conv2d_std_per_chan_sym8sxasym8s
  xa_nn_conv2d_depthwise_per_chan_sym8sxasym8s
+ Improves performance on new HiFi5 (LX7.1.9 and onwards) using new ISA for
  following kernels:
  xa_nn_vec_sigmoid_asym8s_asym8s
  xa_nn_vec_sigmoid_16_16
  xa_nn_vec_tanh_asym8s_asym8s
  xa_nn_vec_tanh_16_16
+ Increases support for axis dimensions upto 1024 from 127 in kernel
  xa_nn_reduce_mean_4D_asym8s_asym8s
+ Fixes mismatch w.r.t to TFLM in kernel xa_nn_vec_hard_swish_asym8s_asym8s.
+ Fixes range of input, output shifts in element wise add/sub kernels from 
  -31 to 31 to -31 to 0.
+ Fixes input_range_radius check in xa_nn_vec_tanh_asym8s_asym8s,
  xa_nn_vec_sigmoid_asym8u_asym8u and xa_nn_vec_sigmoid_asym8s_asym8s.
+ Fixes input_zero_bias range in xa_nn_vec_leaky_relu_asym8s_asym8s to match
  with TFLM Ref.

-------------------------------------------------------------------------------

Version 1.7.0 API 1.1: February 1, 2022

+ GA Release of HiFi 5 NN Library.
+ NN Library for HiFi 5 DSPs with the NN Extension and optional SP-VFP Unit
+ Tested using RI.6 tools, xt-clang compiler.
+ Fixes following issues:
  Fixes hang in matXvec sample testbench.(TENA-3062)
  Adds -Wsign-compare flag in build set up. (TENA-2953)
  Fixes crash in Fully Connected float32 kernel. (TENA-3054)
  Allows null bias for matmul (8x8, asym8xasym8 and sym8sxasym8s) kernels (TENA-3090)
  Allows null bias for fully connected (sym8sxasym8s) kernel. (TENA-3091)

-------------------------------------------------------------------------------

Version 1.6.0 API 1.0: June 30, 2021

+ Intermediate Release of HiFi5 NN Library
+ Tested using RI.6 tools, xt-clang compiler.
+ Improves performance on new HiFi5 (LX7.1.6 and onwards) using new ISA for
  following kernels:
  xa_nn_conv2d_std_per_chan_sym8sxasym8s
  xa_nn_matXvec_sym8sxasym8s_asym8s
  xa_nn_matXvec_out_stride_sym8sxasym8s_16
  xa_nn_dilated_conv2d_std_per_chan_sym8sxasym8s
  xa_nn_conv2d_depthwise_per_chan_sym8sxasym8s
  xa_nn_conv2d_depthwise_asym8uxasym8u
  xa_nn_fully_connected_sym8sxasym8s_asym8s
  xa_nn_conv2d_pointwise_per_chan_sym8sxasym8s
+ Adds support for strides in Dilated Standard 2D Convolution.
+ Adds support for asymmetric quantized 8 bit (int8) variants of following
  TFLM operators:
  LEAKY_RELU
  DEPTH_TO_SPACE
  PAD
  PAD_V2
  BATCH_TO_SPACE_ND
  SPACE_TO_BATCH_ND
+ Adds support for single precision float (float32) variants of following
  TFLM operators:
  ADD
  ABS
  SIN
  COS
  LOG
  SQRT
  RSQRT
  SQUARE
  FILL
  CEIL
  ROUND
  NEG
+ Adds 16-bit input/output variants for sigmoid and tanh kernels based on 
  Tensorflow.
+ Adds matXvec batch kernel with accumulation (8-bit input, sym8s kernel and
  asym16s output).
+ Adds support for TFLM Dequantize (int8 to float32) operators.
+ Adds support for additional data types (int8 to int32, int16 to int32) for 
  TFLM Quantize operator.
+ Adds space_to_depth kernel for 8-bit datatype.
+ Adds broadcast kernel for int8 data type.

-------------------------------------------------------------------------------

Version 1.5.0 API 1.0: February 22, 2021

+ Intermediate Release of HiFi 5 NN Library
+ Tested using RI.5 tools, xt-xcc/xt-xc++ and xt-clang/xt-clang++ compiler
+ Adds support for asymmetric quantized 8 bit (int8) variants of 
  following TFLM operators
  L2Normalization
  LogicalAND
  LogicalOR
  LogicalNOT
  ReduceMax
  ReduceMean
+ Adds support for dilation with standard convolution operation
+ Adds broadcast variants of elementwise minimum and maximum kernels for int8
  data type
+ Adds TFLM speech commands example application replacing earlier NN examples


Known issues
> Standard convolution with dilation currently does not support stride values
  greater than one.

-------------------------------------------------------------------------------

Version 1.4.0 API 1.0: January 11, 2021

+ Intermediate Release of HiFi 5 NN Library
+ Tested using RI.5 tools, xt-xcc/xt-xc++ and xt-clang/xt-clang++ compiler
+ Adds support for asymmetric quantized 8 bit (int8) variants of 
  following TFLM operators
    Equal
    Greater
    GreaterEqual
    Hardswish
    Less
    LessEqual
    Logistic 
    Maximum
    Minimum
    NotEqual
    Prelu
    Sub
    Tanh
+ [TENA-2706] Updated Relu implementation for asymmetric quantized 8 bit
  variants (asym8s and asym8u) as per latest TFLM reference implementation. 

-------------------------------------------------------------------------------

Version 1.3.0 API 1.0: Novmeber 12, 2020

+ Intermediate Release of HiFi 5 NN Library
+ Tested using RI.5 tools, xt-xcc/xt-xc++ and xt-clang/xt-clang++ compiler
+ Adds support for asymmetric quantized 8 bit (int8) variants of 
  following TFLM operators
    Add
    AveragePool2D
    Conv2D (Standard convolution and pointwise convolution)
    MaxPool2D
    Mul
+ Adds support for float32 variants of following TFLM operators
    floor
+ Adds optimizations in depthwise convolution for 3x3 kernel size, int8 variant

-------------------------------------------------------------------------------

Version 1.2.1 API 1.0: September 17, 2020

+ Patch release 
+ Tested using RI.2 tools and xt-xcc/xt-xc++ compiler
+ Adds a fix to avoid symbols clash with NatureDSP Library. 

-------------------------------------------------------------------------------

Version 1.2.0 API 1.0: September 3, 2020

+ Intermediate Release of HiFi 5 NN Library
+ Tested using RI.2 tools and xt-xcc/xt-xc++ compiler
+ Adds support for quantized 8 bit variants of following kernels of TFLM
    SVDF (Keyword benchmark support)
    Standard convolution 
    Average pooling 
    Quantization
+ Other miscellaneous optimization improvements

-------------------------------------------------------------------------------

Version 1.1.0 API 1.0: July 15, 2020

+ Intermediate Release of HiFi 5 NN Library
+ Tested using RI.2 tools and xt-xcc/xt-xc++ compiler
+ Adds support for quantized 8 bit variants of following kernels of TFLM
    Depthwise convolution 
    Fully connected
    Softmax
+ Other miscellaneous optimization improvements

-------------------------------------------------------------------------------

Version 1.0.0 API 1.0: July 23, 2019

+ GA Release of HiFi 5 NN Library
+ NN Library for HiFi 5 DSPs with the NN Extension and optional SP-VFPU
+ Implements the following low level kernels:
    Matrix-vector multiplication kernels
    Convolution kernels
    Activation kernels
    Pooling kernels 
+ Implements the following NN layers using the "generic NN Layer API":
    GRU layer
    LSTM layer
    CNN layer

-------------------------------------------------------------------------------
